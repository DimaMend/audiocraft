# @package __global__

# This is the training loop solver
# for the base MusicGen model (text-to-music)
# on monophonic audio sampled at 32 kHz
defaults:
  - musicgen_sourcesep/default
  - /model: lm/musicgen_lm
  - override /dset: audio/default
  - _self_

autocast: true
autocast_dtype: float16

# We trained 3 specialized EnCodec models
# with a total stride of 640 leading to 50 frames/s.
# rvq.bins=2048, no quantization dropout
# The drums and the bass model only have one single stream of quantization
# For the other stem there are 4 streams of Residual Vector Quantization.
multistem_compression_model_checkpoints:
  # Here we use pretrained model with all the stems in 'pretrained'
  sources: ['bass', 'drums', 'other']
  pretrained: 'facebook/encodec_32_khz_bass_1_drums_1_other_4'
  bass:
  drums:
  other:

channels: 1
sample_rate: 32000

deadlock:
  use: true  # deadlock detection

dataset:
  batch_size: 192  # 32 GPUs
  sample_on_weight: false  # Uniform sampling all the way
  sample_on_duration: false  # Uniform sampling all the way

generate:
  lm:
    use_sampling: true
    top_k: 250
    top_p: 0.0

optim:
  epochs: 500
  optimizer: dadam
  lr: 1
  ema:
    use: true
    updates: 10
    device: cuda

logging:
  log_tensorboard: true

schedule:
  lr_scheduler: cosine
  cosine:
    warmup: 4000
    lr_min_ratio: 0.0
    cycle_length: 1.0
