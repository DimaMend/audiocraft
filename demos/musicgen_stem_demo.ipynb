{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicGen-Stem\n",
    "Welcome to MusicGen-Stem's demo jupyter notebook. Here you will find a series of self-contained examples of how to use MusicGen-Stem in different settings.\n",
    "\n",
    "First, we start by initializing MusicGen-Stem, you can choose a model from the following selection:\n",
    "1. `facebook/musicgen-stem-6cb` - 1.5B transformer decoder with 1 codebook for bass, 1 codebook for drums and 4 codebooks for other. It is the model that is showcased in the MusicGen-Stem paper.\n",
    "2. `facebook/musicgen-stem-7cb` - 1.5B transformer decoder with 2 codebooks for bass, 1 codebook for drums and 4 codebooks for other. This model is not showcased in the MusicGen-Stem paper but has been developed in order to have a better sounding bass. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from audiocraft.utils.notebook import display_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import MusicGenStem\n",
    "\n",
    "# Choose a model between these two:\n",
    "\n",
    "# model = MusicGenStem.get_pretrained('facebook/musicgen-stem-6cb')\n",
    "model = MusicGenStem.get_pretrained('facebook/musicgen-stem-7cb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us configure the generation parameters. Specifically, you can control the following:\n",
    "* `use_sampling` (bool, optional): use sampling if True, else do argmax decoding. Defaults to True.\n",
    "* `top_k` (int, optional): top_k used for sampling. Defaults to 250.\n",
    "* `top_p` (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.\n",
    "* `temperature` (float, optional): softmax temperature parameter. Defaults to 1.0.\n",
    "* `duration` (float, optional): duration of the generated waveform. Defaults to 30.0.\n",
    "* `cfg_coef` (float, optional): coefficient used for classifier free guidance. Defaults to 3.0.\n",
    "* `double_cfg` (bool, optional): If True, use double CFG. Defaults to False.\n",
    "\n",
    "\n",
    "When left unchanged, MusicGen will revert to its default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=250,\n",
    "    duration=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can perform text-to-music generation, music continuation, text condition instrument regeneration from a mixture or from stems.\n",
    "* Text-to-music can be done using `model.generate`, or `model.generate_with_chroma` with the wav condition being None. \n",
    "* Style-to-music and Text-and-Style-to-music can be done using `model.generate_with_chroma`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.set_generation_params(\n",
    "    duration=8, # generate 8 seconds, can go up to 30\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "descriptions=[\n",
    "        '80s pop track with bassy drums and synth',\n",
    "        '90s rock song with loud guitars and heavy drums',\n",
    "        'EDM inspiring song',\n",
    "        'Bluesy guitar instrumental with soulful licks and a driving rhythm section',\n",
    "        'Funky song with a strong bassline and a dancy feeling',\n",
    "    ]\n",
    "\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=descriptions,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "# We create the mixture by summing the bass, drums and other\n",
    "output[0]['mixture'] = sum(output[0].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we listen to each stem as well as the mixture, song by song\n",
    "\n",
    "for idx, description in enumerate(descriptions):\n",
    "    print(description)\n",
    "    for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "        print(stem)\n",
    "        display_audio(output[0][stem][idx], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the continuation of an existing mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture, sr = torchaudio.load('../assets/electronic.mp3')\n",
    "display_audio(mixture, sample_rate=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate_continuation_from_mixture(\n",
    "    mixture=mixture, mixture_sample_rate=sr,\n",
    "    descriptions=['dancy electronic song'],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "# We create the mixture by summing the bass, drums and other\n",
    "output[0]['mixture'] = sum(output[0].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the continuation of a song from its codes (tokens)\n",
    "Given some generated codes (that we can obtain with a song that we generate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=5, # generate 4 seconds, can go up to 30\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=['Folk song with an acoustic guitar'],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n",
    "\n",
    "# We can extract the codes, since we used the argument return_tokens=True\n",
    "codes = output[1]\n",
    "print(codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given the codes of the generated song, we can extend it with a different prompt and see how the model switches from one genre to another. The transition is not necesseraly very smooth but the continuation function can be useful when the user generates a few seconds, listen to it and then decides to generate the continuation if they enjoy the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to extend the duration, let's say to 10 seconds\n",
    "\n",
    "model.set_generation_params(\n",
    "    duration=10,\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.generate_continuation_from_codes(\n",
    "    codes=codes,\n",
    "    descriptions=['Folk song with drums and an electric guitar'],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regenerate stems on an existing song (mixture)\n",
    "To do so, the user needs to load an existing song. The song can be in mono or stereo in any sample rate the model will convert it in 32khz mono, separate it with demucs and replace the desired stems. The model is made for 25 seconds excerpts. If the song is longer, only the first 25 seconds will be taken into account, if shorter the song will be padded with zeros. \n",
    "You need to use the ```regenerate_instruments_from_mixture``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load a 25 seconds excerpt of a song\n",
    "path_source = '../assets/pop_song.wav'\n",
    "\n",
    "mixture, sr = torchaudio.load(path_source)\n",
    "\n",
    "display_audio(mixture, sample_rate=sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's regenerate the bass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_instruments_from_mixture(\n",
    "    mixture=mixture,\n",
    "    mixture_sample_rate=sr,\n",
    "    which_instruments_regenerate=['bass'], # list of stems that you want to replace\n",
    "    descriptions=['Pop song with a funky bass'], # put any prompt that you want\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's regenerate the drums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_instruments_from_mixture(\n",
    "    mixture=mixture,\n",
    "    mixture_sample_rate=sr,\n",
    "    which_instruments_regenerate=['drums'], # list of stems that you want to replace\n",
    "    descriptions=['Upbeat drums, pop song'], # put any prompt that you want\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's regenerate the other stems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_instruments_from_mixture(\n",
    "    mixture=mixture,\n",
    "    mixture_sample_rate=sr,\n",
    "    which_instruments_regenerate=['other'], # list of stems that you want to replace\n",
    "    descriptions=['Pop song with a piano'], # put any prompt that you want\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's regenerate the bass and the other stems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_instruments_from_mixture(\n",
    "    mixture=mixture,\n",
    "    mixture_sample_rate=sr,\n",
    "    which_instruments_regenerate=['bass', 'other'], # list of stems that you want to replace\n",
    "    descriptions=['Pop song with an acoustic guitar and an upbeat drums'], # put any prompt that you want\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regenerate from audio stems. \n",
    "If you already have audio stems, (e.g. a drum loop, you can generate the bass and other instruments). \n",
    "For this you need to use the ```regenerate_instruments_from_stems``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some drums\n",
    "\n",
    "drums, sr = torchaudio.load('../assets/drum_loop.wav')\n",
    "\n",
    "display_audio(drums, sample_rate=sr)\n",
    "\n",
    "stems = {'drums': drums}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_instruments_from_stems(\n",
    "    stems=stems,\n",
    "    stems_sample_rate=sr,\n",
    "    which_instruments_regenerate=['bass', 'other'], # list of stems that you want to replace\n",
    "    descriptions=['House song with synth pads with a groovy bassline. Uplifting feeling'],\n",
    "    progress=True, return_tokens=True,\n",
    "    return_non_compressed_stems=True, # for the input stems, we return the original ones instead of the compressed ones\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regenerate from codes.\n",
    "This function is useful for regenerating some stems from codes. The typical usecase is if we generate a song from scratch with MusicGen-Stem and want to regenerate some stems. We then use the ```regenerate_from_codes``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=10, # generate 4 seconds, can go up to 30\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=['Folk song with drums, bass and an acoustic guitar'],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n",
    "\n",
    "# We can extract the codes, since we used the argument return_tokens=True\n",
    "codes = output[1]\n",
    "print(codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given the codes, we want to regenerate some stems (e.g. the bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    duration=15, # The final length will be duration-5. You need to put 30 if you want to regenerate all of the 25 secs\n",
    "    use_sampling=True, \n",
    "    top_k=250,\n",
    "    cfg_coef=3., # Classifier Free Guidance coefficient \n",
    ")\n",
    "\n",
    "output = model.regenerate_from_codes(\n",
    "    codes=codes,\n",
    "    which_instruments_regenerate=['bass'], # list of stems that you want to replace\n",
    "    descriptions=['Folk song with drums, bass and an acoustic guitar'], # put any prompt that you want\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "\n",
    "output[0]['mixture'] = sum(output[0].values())\n",
    "\n",
    "for stem in ['bass', 'drums', 'other', 'mixture']:\n",
    "    print(stem)\n",
    "    display_audio(output[0][stem], sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b02c911f9b3627d505ea4a19966a915ef21f28afb50dbf6b2115072d27c69103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
